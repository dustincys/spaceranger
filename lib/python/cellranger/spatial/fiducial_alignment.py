#!/usr/bin/env python
#
# Copyright (c) 2019 10X Genomics, Inc. All rights reserved.
#
from collections import namedtuple
import cv2
import numpy as np
from cellranger.spatial.pycpd.rigid_registration import rigid_registration
from cellranger.spatial.pycpd.affine_registration import affine_registration
import cellranger.spatial.manual_alignment as ma_utils
import cellranger.spatial.utils as spatial_utils

from scipy.stats import gaussian_kde
from scipy.signal import argrelmax, argrelmin

def get_blob_size_threshold(blob_sizes, mindist):
    """given blob size distribution, and minimum distance between blobs, obtain a threshold on blob size"""
    _, bins = np.histogram(blob_sizes, bins=50, density=True)
    density = gaussian_kde(blob_sizes)
    signal = density(bins)

    # get peaks and valleys in smoothed histogram
    peaks = argrelmax(signal)[0]
    valleys = argrelmin(signal)[0]

    # find up to 3 tallest peaks reverse sorted by size. Discard 1st peak if tiny and set farthest relevant peak
    farthest_peaks = sorted(sorted(zip(signal[peaks], peaks), reverse=True)[0:min(3, len(peaks))],
                            key=lambda v: v[1], reverse=True)
    farthest_peak = farthest_peaks[1][1] if farthest_peaks[0][0] < 0.12 * np.max(signal) and \
        len(farthest_peaks) > 2 else farthest_peaks[0][1]

    # find valley prior to farthest peak and return as threshold on blob size
    threshold = bins[valleys[valleys < farthest_peak][-1]] if np.any(valleys < farthest_peak) else \
        bins[farthest_peak] - mindist
    return threshold, bins[farthest_peak]

def get_cv_adjusted_image(cvimg, target):
    """Scale image to match the longest side with target pixel size"""
    scalef = 1.0 * target / max(cvimg.shape)
    rcvimg = cv2.resize(cvimg, (0, 0), fx=scalef, fy=scalef)
    return rcvimg

def detect_fiducials(original_image, minsize=10):
    """Fiducial detection based on opencv method: simpleblobDetector. Detects features of minimum 10px/blob
    by first standardizing the image to fixed pixel dimensions, then performing blob detection, and then filtering
    blobs detected based on their size in a data-driven manner"""

    # Force image to be of a target size so that everything else can be standardized with respect to it.
    image = original_image #get_cv_adjusted_image(original_image, target=3000)

    # blob detector params
    params = cv2.SimpleBlobDetector_Params()
    params.filterByCircularity = True
    params.minCircularity = 0.8   # keep regular circular shapes
    params.filterByInertia = True
    params.minInertiaRatio = 0.5  # circle has inertia 1, ellipse 0-1, line 0
    params.filterByColor = False  # treat as greyscale
    params.thresholdStep = 1.0
    params.minThreshold = 10
    params.maxThreshold = 255     # no effect, but image max is 255

    # aggressively detect blobs
    detector = cv2.SimpleBlobDetector_create(params)

    # below - scaling minsize for blurring slightly because this was optimized for 3K images and now we're at 2K
    # This was necessary to avoid obliterating contrast in some images.
    keypoints = detector.detect(cv2.blur(image, (int(minsize*0.75+0.5), int(minsize*0.75+0.5))).astype('uint8'))

    # signal processing to find cutoff size and filter
    if len(keypoints) > 0:
        blob_sizes = np.array([x.size for x in keypoints])
        threshold, mean_size = get_blob_size_threshold(blob_sizes, minsize)
        seed_keypoints = [k for k in keypoints if k.size >= threshold]

        other_keypoints = [k for k in keypoints if k.size < threshold]
        final_keypoints = seed_keypoints[:]

        if len(seed_keypoints) < 400:
            ## do an iteration to grab more keypoints within distance approx 2*mean fiducial size. Can be slow
            for ki in range(len(seed_keypoints)):
                for kj in range(len(other_keypoints)):
                    dist = np.sqrt((seed_keypoints[ki].pt[0] - other_keypoints[kj].pt[0]) ** 2 + (seed_keypoints[ki].pt[1] - other_keypoints[kj].pt[1]) ** 2)
                    if 1.7 * mean_size <= dist <= 2.3 * mean_size:
                        final_keypoints += [other_keypoints[kj]]

        # sort-uniq the final keypoints, sorting based on location
        # to ensure stability for testing
        keypoints=[]
        for i, kp in enumerate(sorted(final_keypoints, key=lambda k: (k.pt[0], k.pt[1]))):
            if i == 0 or kp != keypoints[-1]:
                keypoints.append(kp)

    return keypoints

def align_fiducials_from_override(tissue_image, iscale, spot_data,
                             spot_positions_path, fiducial_positions_path,
                             fiducial_image_path):
    """
    Generate a spot positions list and fiducial image from a spot_data
    file generated by Loupe.  Return the diameters of fiducial and spot
    sizes downscaled by iscale.
    """
    fiducial_diameter = np.mean( [s['dia'] for s in spot_data['fiducial']] )       # in fullres image pixels
    spot_diameter     = np.mean( [s['dia'] for s in spot_data['oligo']] )          # in fullres image pixels
    qc = cv2.cvtColor(tissue_image, cv2.COLOR_GRAY2RGB)
    image_spot_locations = ma_utils.read_fiducial_locations_from_alignment(spot_data)
    scaled_spot_locations = [[val*iscale for val in spot] for spot in image_spot_locations]
    spatial_utils.write_aligned_fiducials_image(qc, scaled_spot_locations, fiducial_diameter*iscale, fiducial_image_path)
    ma_utils.write_fiducial_positions_list_from_alignment(spot_data, fiducial_positions_path)
    ma_utils.write_spot_positions_list_from_alignment(spot_data, spot_positions_path)

    return ( fiducial_diameter*iscale, spot_diameter*iscale )


def compute_spot_sizes_from_gpr_data(gpr_data, trans):
    """
    Given GPR data and a transform from GPR image space (microns) to user tissue image space, compute the pixel
    diameter of fiducials and spots in user tissue image space.

    transform should be a pre-multiply transform taking us from GPR space to user image space
    """
    fiducial_mean_gpr = np.mean( [ float(s["dia"]) for s in gpr_data["fiducial"] ] )
    spot_mean_gpr = np.mean( [ float(s["dia"]) for s in gpr_data["oligo"] ] )

    scale = np.mean( np.linalg.norm(trans, axis=1) )    # in theory, the norm of both rows should be the same

    return scale * fiducial_mean_gpr, scale * spot_mean_gpr


def align_fiducials_5k(tissue_image, iscale, spot_data, transform_method,
                       spot_positions_path, fiducial_positions_path,
                       fiducial_image_path, keypoint_image_path, fast = False, keypoints=None):
    """
    Align the input fiducials to the fiducial image, generating spot locations,
    an image superimposed with detected fiducials, and an image superimposed with detected keypoints.

    :param tissue_image:  The input tissue image.
    :param iscale:  The downsample factor between original image and generated stage images.
    :param spot_data: A JSON file containing expected fiducial spot locations.
    :param transform_method:
    :param spot_positions_path: The local path at which to write the spot locations file.
    :param fiducial_positions_path: The local path at which to write the fiducial locations file.
    :param fiducial_image_path: The local path at which to write the image overlaid with fiducials.
    :param keypoint_image_path: The local path at which to write the image overlaid with detected keypoints.
    :param fast: if true, calls run_regisration requesting fewer iterations
    :param keypoints: allows passing in a keypoint set for testing

    returns RegMetrics (see below), (fiducial_diameter, spot_diameter) in (fractional) tissue_image pixels
    """
    ### Detect the fiducial keypoints
    if keypoints is None:
        keypoints = detect_fiducials(tissue_image, minsize=10)
        if len(keypoints) < 10:
            raise RuntimeError("Too few keypoints detected")

    fiducial_xy = np.array([ [pt['x'], pt['y'], 1] for pt in spot_data['fiducial']])

    ### Prepare the algorithm inputs
    dest = fiducial_xy[:,0:2].astype('double')                 # A
    src  = np.array([x.pt for x in keypoints], dtype='double') # B
    dest_points = dest - np.median(dest, 0)
    src_points  = src - np.median(src, 0)

    ### Run the CPD algorithm to do the fiducial alignment
    B_inverse, t_inverse, reg_metrics = run_registration(dest_points, src_points, transform_method, fast)

    # Compute the transform matrix
    A_to_B = np.dot(dest_points + np.tile(t_inverse, (dest_points.shape[0], 1)), B_inverse)
    A_to_B = A_to_B + np.median(src, 0)
    A_to_B_int = [[int(round(coord/iscale)) for coord in point] for point in A_to_B]
    fiducial_array = [[fid['row'], fid['col'], y, x] for (fid, (x, y)) in zip(spot_data['fiducial'], A_to_B_int)]
    spatial_utils.write_to_list(fiducial_positions_path, fiducial_array)

    ### Transform the spot coordinates and write to file
    transformed_coordinates = spatial_utils.transform_oligo_locations(spot_data, dest, src, B_inverse, t_inverse, iscale)
    spatial_utils.write_to_list(spot_positions_path, transformed_coordinates)

    # compute fiducial sizes from alignment and average spot sizes in the GPR file
    fid_dia, spot_dia = compute_spot_sizes_from_gpr_data(spot_data, B_inverse.T)    # pass transpose because we specify pre-multiply matrix

    # Make a QC image overlaying the detected keypoints on the image
    qc = cv2.cvtColor(tissue_image, cv2.COLOR_GRAY2RGB)
    spatial_utils.write_detected_keypoints_image(qc, keypoints, fid_dia, keypoint_image_path)

    # Make a QC image overlaying the aligned fiducials on the image
    spatial_utils.write_aligned_fiducials_image(qc, A_to_B, fid_dia, fiducial_image_path)

    return reg_metrics, (fid_dia, spot_dia)


class Visualize:
    """ Helper method for generating HTML5 video of fiducial alignment """
    def __init__(self):
        raise RuntimeError("Visualize() is just a container for a classmethod")

    allY = []
    allX = []

    @classmethod
    def plot_arrays(cls, iteration, error, X, Y):
        """ X is the slide, Y is the fiducials """

        if iteration == 0:
            cls.allY = []
            cls.allX = []
            return

        cls.allY.append(Y.T)
        cls.allX.append(X.T)


def _initialize_scale_from_data(dest_points, src_points):
    """
    calculate the intial scale from the bounding box of points in each point set.
    """
    dx,dy = np.max(dest_points,axis=0) - np.min(dest_points, axis=0)
    sx,sy = np.max(src_points, axis=0) - np.min(src_points, axis=0)

    scale = min( float(dx)/sx, float(dy)/sy )  # min so one fits within the other

    return scale


RegMetricsBase = namedtuple("RegMetricsBase",["mse","sigma2","scale","rad","nfids","trans"])

class RegMetrics(RegMetricsBase):
    def test(self):
        if np.abs(self.rad) > np.pi / 4:
            return "The alignment implies an extreme rotation that is unlikely to be correct"
        elif self.scale < 0.25:
            return "The alignment implies an extreme scaling that is unlikely to be correct"

        return None


def run_registration(dest_points, src_points, method, fast = False):
    """
    run either method = "affine" or method = "rigid" registration from src_points to dst_points

    src_points should be the "noisy" dataset, while dest_points should be the template
    specify fast=True in order to run fewer iterations and less precision - slightly faster for testing with minimal true
    loss of accuracy.
    """


    if fast:
        max_iterations = 80
        tolerance = 0.0001
    else:
        max_iterations = 300
        tolerance = 0.00000001

    if method == "rigid":
        s_init = _initialize_scale_from_data(dest_points, src_points)
        prior_weight = 0.000002    # empirically determined and only used for ; likely just needs to be a hair above zero to allow rare events to be rare,
        # rather than impossible.
        reg = rigid_registration(**{ 'X': dest_points, 'Y': src_points, 'max_iterations': max_iterations, 'tolerance': tolerance, 's': s_init, 'w': prior_weight})
        _, (s, R, t), mse = reg.register(Visualize.plot_arrays)
        B = np.multiply(s, R)
    elif method == "affine":
        reg = affine_registration(**{ 'X': dest_points, 'Y': src_points, 'max_iterations': max_iterations})
    else:
        raise ValueError('Unsupported transformation algorithm: %s' % method)
    B_inverse = np.linalg.inv(B)

    return B_inverse, -t, RegMetrics(mse=mse, sigma2=reg.sigma2, scale=s, rad=np.arccos(R[0][0]), nfids=len(src_points), trans=t)
